# ExoGS

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.10+-blue.svg" alt="Python">
  <img src="https://img.shields.io/badge/PyTorch-2.0+-red.svg" alt="PyTorch">
  <img src="https://img.shields.io/badge/CUDA-12.8-green.svg" alt="CUDA">
  <img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License">
</p>

**ExoGS: A 4D Real-to-Sim-to-Real Framework for Scalable Manipulation Data Collection**

Yiming Wang, Ruogu Zhang, Minyang Li, Hao Shi, Junbo Wang, Deyi li, Weiming Wang, Hao-Shu Fang

ExoGS is a robotfree 4D Real-to-Sim-to-Real framework that captures both static environments and dynamic interactions in the real world and
transfer seamlessly to a simulated environment. It provides a new solution for scalable manipulation data collection and policy learning. ExoGS employs a self-designed robot-isomorphic passive exoskeleton AirExo-3 to capture kinematically consistent trajectories with millimeter-level accuracy and synchronized RGB observations during direct human manipulation. The robot, objects, and environment are reconstructed as editable 3D
Gaussian Splatting assets, enabling geometry-consistent replay and large-scale data augmentation. Additionally, a lightweight Mask Adapter injects instance-level semantics into the policy to enhance robustness under visual domain shifts. 

---

## ðŸŒŸ Highlights

- **Exoskeleton Teleoperation**: Intuitive demonstration collection using wearable exoskeleton devices
- **3D Gaussian Splatting**: High-fidelity scene reconstruction and rendering for data augmentation
- **Mask Adapter**: Lightweight semantic guidance for sim-to-real domain adaptation
- **End-to-End Pipeline**: Complete workflow from data collection to real-world deployment

---

## ðŸ“‹ Table of Contents

- [ExoGS](#exogs)
  - [ðŸŒŸ Highlights](#-highlights)
  - [ðŸ“‹ Table of Contents](#-table-of-contents)
  - [Overview](#overview)
  - [Repository Structure](#repository-structure)
  - [Installation](#installation)
    - [Prerequisites](#prerequisites)
    - [Module-Specific Installation](#module-specific-installation)
  - [Pipeline](#pipeline)
  - [Data Format](#data-format)
    - [Raw Data (CapExo Output)](#raw-data-capexo-output)
    - [Processed Data (GaussianSim Output)](#processed-data-gaussiansim-output)
    - [Training Data (HDF5)](#training-data-hdf5)
  - [Citation](#citation)
  - [Acknowledgements](#acknowledgements)
  - [License](#license)

---

## Overview

ExoGS addresses the sim-to-real gap in robot learning through a novel pipeline that:

1. **Collects** real-world demonstrations via exoskeleton teleoperation
2. **Reconstructs** scene and object assets using 3D Gaussian Splatting
3. **Augments** training data through photorealistic Gaussian rendering
4. **Learns** robust policies with a Mask Adapter that focuses on task-relevant features
5. **Deploys** trained policies on real robotic systems

**Overview of the pipeline for reconstructing manipulation demonstrations :**

<p align="center">
  <img src="asset/GSpipeline.png" width="80%">
</p>

**Overview of the proposed Mask Adapter:**

<p align="center">
  <img src="asset/maskpipeline.png" width="80%">
</p>

## Repository Structure

```
ExoGS/
â”œâ”€â”€ CapExo/              # Data collection with exoskeleton teleoperation
â”‚   â”œâ”€â”€ collect_data.py  # Synchronized encoder and camera data collection
â”‚   â””â”€â”€ postprocess.py   # Timestamp alignment and data formatting
â”‚   
â”œâ”€â”€ DataProcess/         # Data processing and annotation
â”‚   â”œâ”€â”€ data_processor_1.py    # Frame cropping and data organization
â”‚   â”œâ”€â”€ data_processor_2.py    # Mask backfilling
â”‚   â”œâ”€â”€ FoundationPose/        # 6D pose estimation and tracking
â”‚   â””â”€â”€ X-AnyLabeling/         # Mask annotation tool
â”‚
â”œâ”€â”€ PoseProcess/         # Pose processing and post-processing
â”‚   â”œâ”€â”€ scripts/         # Pose collection, processing, and verification
â”‚   â””â”€â”€ poseprocess/     # Core pose processing library
â”‚
â”œâ”€â”€ GSAssetGen/          # Gaussian model asset generation
â”‚   â”œâ”€â”€ sapien/          # SAPIEN-based COLMAP dataset generation
â”‚   â””â”€â”€ scripts/         # Video to image conversion
â”‚
â”œâ”€â”€ GaussianSim/         # 3D Gaussian Splatting rendering
â”‚   â”œâ”€â”€ gaussiansim/     # Core rendering library
â”‚   â”œâ”€â”€ scripts/         # Rendering scripts
â”‚   â””â”€â”€ convert_to_train/  # HDF5 conversion for training
â”‚
â”œâ”€â”€ Mask_Policy/         # Policy learning with Mask Adapter
â”‚   â”œâ”€â”€ maskpolicy/      # Mask policy implementation
â”‚   â””â”€â”€ train/           # Training configurations and scripts
â”‚
â””â”€â”€ CmdExo/              # Real robot deployment
    â”œâ”€â”€ rollout.py       # Hardware control node
    â””â”€â”€ inference.py     # Policy inference node
```

---

## Installation

### Prerequisites

  - Intel RealSense D415 camera
  - Flexiv Rizon robot arm (for deployment)
  - Xense gripper (for deployment)
  - Exoskeleton device (for data collection)

### Module-Specific Installation

Each module has its own environment to avoid dependency conflicts. Please refer to the README in each module directory for detailed installation instructions.

---

## Pipeline

**Pipeline Flow:**

```
  CapExo
     â†“
DataProcess
     â†“
PoseProcess   GSAssetGen
     â†“            â†“               
      GaussianSim
           â†“
      Mask_Policy
           â†“
      CmdExo
```

---

## Data Format

### Raw Data (CapExo Output)
```
<timestamp>/
â”œâ”€â”€ encoder/
â”‚   â”œâ”€â”€ angle.npy
â”‚   â””â”€â”€ timestamps.npy
â””â”€â”€ camera/
    â”œâ”€â”€ color/
    â”œâ”€â”€ depth/
    â”œâ”€â”€ timestamps.npy
    â””â”€â”€ intrinsics.txt
```

### Processed Data (GaussianSim Output)
```
GSData/
â””â”€â”€ records_xxxx/
    â””â”€â”€ record_xxxx/
        â”œâ”€â”€ angles/          # Robot joint angles
        â”œâ”€â”€ tcps/            # TCP poses
        â””â”€â”€ cam_0/
            â”œâ”€â”€ rgbs_bg0/    # RGB images
            â”œâ”€â”€ depths/      # Depth maps
            â”œâ”€â”€ masks/       # Segmentation masks
            â””â”€â”€ masks_clean_labels/
```

### Training Data (HDF5)
```
data/
â”œâ”€â”€ demo_0/
â”‚   â”œâ”€â”€ images   (N, H, W, 3) uint8
â”‚   â”œâ”€â”€ masks    (N, H, W, 3) uint8
â”‚   â”œâ”€â”€ joints   (N, num_joints) float64
â”‚   â””â”€â”€ tcps     (N, 10) float64
â””â”€â”€ demo_1/
    â””â”€â”€ ...
```

---

## Citation

If you find this work useful, please cite:

```bibtex
@article{exogs2026,
  title={ExoGS: A 4D Real-to-Sim-to-Real Framework for Scalable Manipulation Data Collection},
  author={Yiming Wang, Ruogu Zhang, Minyang Li, Hao Shi, Junbo Wang, Deyi Li, Weiming Wang, Hao-Shu Fang},
  year={2026}
}
```

---

## Acknowledgements

This project builds upon several excellent open-source projects:

- [3D Gaussian Splatting](https://github.com/graphdeco-inria/gaussian-splatting) - 3D scene reconstruction
- [FoundationPose](https://github.com/NVlabs/FoundationPose) - 6D pose estimation and tracking
- [X-AnyLabeling](https://github.com/CVHub520/X-AnyLabeling) - Auto labeling tool
- [LeRobot](https://github.com/huggingface/lerobot) - Robot learning framework
- [SAPIEN](https://sapien.ucsd.edu/) - Physics simulation
- [COLMAP](https://github.com/colmap/colmap) - COLMAP format dataset generation
- [r3kit](https://github.com/dadadadawjb/r3kit) - Robot control toolkit

---

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

Individual modules may have additional licensing terms. Please check the README or LICENSE file in each module directory.

