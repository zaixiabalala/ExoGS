import cv2
import numpy as np
from typing import Tuple, List, Optional, Dict
from sklearn.cluster import KMeans


class MaskCleaner:
    """
    Mask cleaner for processing masks generated by Gaussian rendering.
    Removes noise and artifacts to generate clean masks.
    """
    
    def __init__(self, target_colors: Optional[List[Tuple[int, int, int]]] = None):
        """
        Initialize mask cleaner.
        
        Args:
            target_colors: List of target pure colors (BGR format, 0-255), e.g., [(0,0,0), (255,255,255)]
                          If None, will automatically extract dominant colors from image
        """
        self.target_colors = target_colors
    
    def binarize(
        self,
        image: np.ndarray,
        threshold: int = 127,
        target_white: Tuple[int, int, int] = (255, 255, 255),
        target_black: Tuple[int, int, int] = (0, 0, 0)
    ) -> np.ndarray:
        """
        Binarize image using simple threshold.
        
        Args:
            image: Input image (BGR or RGB, uint8)
            threshold: Threshold (0-255), pixels with brightness > threshold become white
            target_white: Target color for white pixels
            target_black: Target color for black pixels
        
        Returns:
            Processed image
        """
        # Convert to grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Binarize
        _, binary = cv2.threshold(gray, threshold, 255, cv2.THRESH_BINARY)
        
        # Create output image
        output = np.zeros_like(image)
        output[binary == 255] = target_white
        output[binary == 0] = target_black
        
        return output
    
    def adaptive_binarize(
        self,
        image: np.ndarray,
        block_size: int = 11,
        C: int = 2,
        target_white: Tuple[int, int, int] = (255, 255, 255),
        target_black: Tuple[int, int, int] = (0, 0, 0)
    ) -> np.ndarray:
        """
        Adaptive binarization (better for uneven lighting).
        
        Args:
            image: Input image
            block_size: Neighborhood size (must be odd)
            C: Constant subtracted from mean
            target_white: Target color for white
            target_black: Target color for black
        
        Returns:
            Processed image
        """
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Adaptive threshold
        binary = cv2.adaptiveThreshold(
            gray, 255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY,
            block_size, C
        )
        
        output = np.zeros_like(image)
        output[binary == 255] = target_white
        output[binary == 0] = target_black
        
        return output
    
    def color_clustering(
        self,
        image: np.ndarray,
        num_colors: int = 2,
        target_colors: Optional[List[Tuple[int, int, int]]] = None
    ) -> np.ndarray:
        """
        K-means color clustering.
        Cluster all colors in image to specified number of pure colors.
        
        Args:
            image: Input image (BGR, uint8)
            num_colors: Number of colors to cluster
            target_colors: List of target colors (if provided, map cluster results to these colors)
        
        Returns:
            Processed image
        """
        # Reshape image to pixel list
        pixels = image.reshape(-1, 3).astype(np.float32)
        
        # K-means clustering
        kmeans = KMeans(n_clusters=num_colors, random_state=42, n_init=10)
        labels = kmeans.fit_predict(pixels)
        
        # Get cluster centers
        centers = kmeans.cluster_centers_.astype(np.uint8)
        
        # If target colors provided, map cluster centers to target colors
        if target_colors is not None:
            assert len(target_colors) == num_colors, \
                f"target_colors length ({len(target_colors)}) must equal num_colors ({num_colors})"
            
            # Sort cluster centers and target colors by brightness
            centers_brightness = [np.mean(c) for c in centers]
            target_brightness = [np.mean(t) for t in target_colors]
            
            sorted_centers_idx = np.argsort(centers_brightness)
            sorted_target_idx = np.argsort(target_brightness)
            
            # Create mapping
            color_mapping = {}
            for i, center_idx in enumerate(sorted_centers_idx):
                target_idx = sorted_target_idx[i]
                color_mapping[center_idx] = np.array(target_colors[target_idx], dtype=np.uint8)
            
            # Apply mapping
            output_pixels = np.array([color_mapping[label] for label in labels])
        else:
            # Use cluster centers directly
            output_pixels = centers[labels]
        
        # Reshape back to image shape
        output = output_pixels.reshape(image.shape)
        
        return output
    
    def nearest_color_mapping(
        self,
        image: np.ndarray,
        target_colors: List[Tuple[int, int, int]],
        color_space: str = 'BGR'
    ) -> np.ndarray:
        """
        Nearest color mapping.
        Map each pixel to the closest target pure color.
        
        Args:
            image: Input image (uint8)
            target_colors: List of target pure colors, e.g., [(0,0,0), (255,0,0), (0,255,0)]
            color_space: Color space, 'BGR' or 'RGB'
        
        Returns:
            Processed image
        """
        h, w = image.shape[:2]
        output = np.zeros_like(image)
        
        # Convert target colors to numpy array
        targets = np.array(target_colors, dtype=np.float32)
        
        # Find nearest target color for each pixel
        pixels = image.reshape(-1, 3).astype(np.float32)
        
        # Calculate Euclidean distance
        distances = np.zeros((pixels.shape[0], len(targets)))
        for i, target in enumerate(targets):
            distances[:, i] = np.linalg.norm(pixels - target, axis=1)
        
        # Find nearest color
        nearest_idx = np.argmin(distances, axis=1)
        
        # Map to target colors
        output_pixels = targets[nearest_idx].astype(np.uint8)
        output = output_pixels.reshape(image.shape)
        
        return output
    
    def morphology_clean(
        self,
        image: np.ndarray,
        kernel_size: int = 5,
        operations: str = 'open-close'
    ) -> np.ndarray:
        """
        Morphological operations for noise removal.
        
        Args:
            image: Input image
            kernel_size: Kernel size
            operations: Operation sequence
                - 'open': Opening (remove small noise)
                - 'close': Closing (fill small holes)
                - 'open-close': Open then close
                - 'close-open': Close then open
        
        Returns:
            Processed image
        """
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
        
        if operations == 'open':
            result = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)
        elif operations == 'close':
            result = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)
        elif operations == 'open-close':
            opened = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)
            result = cv2.morphologyEx(opened, cv2.MORPH_CLOSE, kernel)
        elif operations == 'close-open':
            closed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)
            result = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel)
        else:
            result = image
        
        return result
    
    def channel_wise_clean(
        self,
        image: np.ndarray,
        target_colors: List[Tuple[int, int, int]],
        tolerance: int = 30
    ) -> np.ndarray:
        """
        Channel-wise cleaning.
        Process each color channel separately to remove near-but-not-pure colors.
        
        Args:
            image: Input image (BGR, uint8)
            target_colors: List of target pure colors
            tolerance: Tolerance value (0-255), pixels within tolerance distance from target color will be forced to target color
        
        Returns:
            Processed image
        """
        output = image.copy()
        
        for target in target_colors:
            target_arr = np.array(target, dtype=np.float32)
            
            # Calculate distance from each pixel to target color
            diff = np.abs(image.astype(np.float32) - target_arr)
            distance = np.linalg.norm(diff, axis=2)
            
            # Force pixels within tolerance to target color
            mask = distance < tolerance
            output[mask] = target
        
        return output
    
    def hybrid_clean(
        self,
        image: np.ndarray,
        target_colors: List[Tuple[int, int, int]],
        method: str = 'cluster-morph',
        **kwargs
    ) -> np.ndarray:
        """
        Hybrid cleaning method (recommended).
        Combines multiple methods for best results.
        
        Args:
            image: Input image
            target_colors: List of target pure colors
            method: Cleaning method
                - 'cluster-morph': Clustering + morphology (recommended)
                - 'nearest-morph': Nearest color + morphology
                - 'binarize-morph': Binarization + morphology (2 colors only)
            **kwargs: Parameters passed to sub-methods
        
        Returns:
            Processed image
        """
        if method == 'cluster-morph':
            # Step 1: K-means clustering to target colors
            cleaned = self.color_clustering(image, len(target_colors), target_colors)
            # Step 2: Morphological denoising
            kernel_size = kwargs.get('kernel_size', 3)
            cleaned = self.morphology_clean(cleaned, kernel_size, 'open-close')
            
        elif method == 'nearest-morph':
            # Step 1: Nearest color mapping
            cleaned = self.nearest_color_mapping(image, target_colors)
            # Step 2: Morphological denoising
            kernel_size = kwargs.get('kernel_size', 3)
            cleaned = self.morphology_clean(cleaned, kernel_size, 'open-close')
            
        elif method == 'binarize-morph':
            assert len(target_colors) == 2, "Binarization mode only supports 2 colors"
            # Step 1: Binarization
            threshold = kwargs.get('threshold', 127)
            cleaned = self.binarize(image, threshold, target_colors[1], target_colors[0])
            # Step 2: Morphological denoising
            kernel_size = kwargs.get('kernel_size', 3)
            cleaned = self.morphology_clean(cleaned, kernel_size, 'open-close')
        
        else:
            cleaned = image
        
        return cleaned


def extract_dominant_colors(image: np.ndarray, num_colors: int = 5) -> List[Tuple[int, int, int]]:
    """
    Extract dominant colors from image.
    
    Args:
        image: Input image (BGR, uint8)
        num_colors: Number of colors to extract
    
    Returns:
        List of dominant colors in BGR format
    """
    pixels = image.reshape(-1, 3).astype(np.float32)
    
    # K-means clustering
    kmeans = KMeans(n_clusters=num_colors, random_state=42, n_init=10)
    kmeans.fit(pixels)
    
    # Get cluster centers
    colors = kmeans.cluster_centers_.astype(np.uint8)
    
    # Sort by frequency
    labels = kmeans.labels_
    counts = np.bincount(labels)
    sorted_indices = np.argsort(-counts)
    
    sorted_colors = [tuple(colors[i]) for i in sorted_indices]
    
    return sorted_colors


def apply_color_threshold(
    image: np.ndarray,
    color_map: Dict[str, Tuple[int, int, int]],
    tolerance: int = 50
) -> np.ndarray:
    """
    Color threshold-based mapping.
    
    Args:
        image: Input image (BGR, uint8)
        color_map: Color mapping dictionary, format:
                  {
                      'black': (0, 0, 0),
                      'red': (0, 0, 255),
                      'green': (0, 255, 0),
                      'blue': (255, 0, 0)
                  }
        tolerance: Tolerance value
    
    Returns:
        Processed image
    """
    output = image.copy()
    
    for color_name, target_color in color_map.items():
        target_arr = np.array(target_color, dtype=np.float32)
        
        # Calculate distance
        diff = np.abs(image.astype(np.float32) - target_arr)
        distance = np.linalg.norm(diff, axis=2)
        
        # Apply mapping
        mask = distance < tolerance
        output[mask] = target_color
    
    return output


def clean_binary_mask(
    mask: np.ndarray,
    min_object_size: int = 100,
    kernel_size: int = 5,
    target_white: Tuple[int, int, int] = (255, 255, 255),
    target_black: Tuple[int, int, int] = (0, 0, 0)
) -> np.ndarray:
    """
    Clean binary classification mask (specialized for object detection).
    
    Processing pipeline:
    1. Convert to grayscale and binarize
    2. Remove small noise
    3. Fill small holes
    4. Force to pure colors
    
    Args:
        mask: Input mask image
        min_object_size: Minimum object size (pixel count), connected components smaller than this will be removed
        kernel_size: Morphological kernel size
        target_white: Object color (foreground)
        target_black: Background color
    
    Returns:
        Cleaned pure mask
    """
    # Convert to grayscale
    if len(mask.shape) == 3:
        gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)
    else:
        gray = mask
    
    # Binarization (Otsu automatic threshold)
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    
    # Morphological operations: opening to remove small noise
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
    
    # Closing to fill small holes
    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel)
    
    # Remove small connected components
    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(cleaned, connectivity=8)
    
    for i in range(1, num_labels):  # Skip background (label 0)
        area = stats[i, cv2.CC_STAT_AREA]
        if area < min_object_size:
            cleaned[labels == i] = 0  # Remove small regions
    
    # Convert to color and force pure colors
    output = np.zeros((mask.shape[0], mask.shape[1], 3), dtype=np.uint8)
    output[cleaned == 255] = target_white
    output[cleaned == 0] = target_black
    
    return output


def clean_instance_mask(
    mask: np.ndarray,
    target_colors: List[Tuple[int, int, int]],
    method: str = 'nearest',
    min_object_size: int = 50,
    kernel_size: int = 3
) -> np.ndarray:
    """
    Clean instance segmentation mask (multiple objects with different colors).
    
    Args:
        mask: Input mask image (BGR, uint8)
        target_colors: List of target colors, e.g., [(0,0,0), (0,0,255), (0,255,0), (255,0,0)]
        method: Cleaning method
            - 'nearest': Nearest color mapping (fast)
            - 'cluster': K-means clustering (accurate)
        min_object_size: Minimum object size
        kernel_size: Morphological kernel size
    
    Returns:
        Cleaned instance mask
    """
    cleaner = MaskCleaner(target_colors)
    
    # Step 1: Color mapping
    if method == 'nearest':
        cleaned = cleaner.nearest_color_mapping(mask, target_colors)
    elif method == 'cluster':
        cleaned = cleaner.color_clustering(mask, len(target_colors), target_colors)
    else:
        cleaned = mask
    
    # Step 2: Morphological cleaning
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_OPEN, kernel)
    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel)
    
    # Step 3: Remove small connected components (process each color separately)
    for target_color in target_colors:
        # Create mask for this color
        color_mask = np.all(cleaned == target_color, axis=2).astype(np.uint8) * 255
        
        # Connected component analysis
        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(color_mask, connectivity=8)
        
        for i in range(1, num_labels):
            area = stats[i, cv2.CC_STAT_AREA]
            if area < min_object_size:
                # Remove small regions (set to black)
                cleaned[labels == i] = (0, 0, 0)
    
    return cleaned


def batch_clean_masks(
    input_folder: str,
    output_folder: str,
    target_colors: List[Tuple[int, int, int]],
    method: str = 'nearest',
    file_pattern: str = '*.png',
    **kwargs
):
    """
    Batch clean masks in folder.
    
    Args:
        input_folder: Input folder path
        output_folder: Output folder path
        target_colors: List of target colors
        method: Cleaning method ('nearest', 'cluster', 'binary')
        file_pattern: File matching pattern
        **kwargs: Additional parameters passed to cleaning functions
    """
    import os
    import glob
    from tqdm import tqdm
    
    os.makedirs(output_folder, exist_ok=True)
    
    # Get all image files
    pattern = os.path.join(input_folder, file_pattern)
    image_files = sorted(glob.glob(pattern))
    
    print(f"[Info] Starting batch mask cleaning, {len(image_files)} images")
    print(f"[Info] Target colors: {target_colors}")
    print(f"[Info] Cleaning method: {method}")
    
    cleaner = MaskCleaner(target_colors)
    
    for img_path in tqdm(image_files, desc="Cleaning masks", unit="img"):
        # Read image
        img = cv2.imread(img_path)
        
        # Clean
        if method == 'binary' and len(target_colors) == 2:
            cleaned = clean_binary_mask(
                img,
                min_object_size=kwargs.get('min_object_size', 100),
                kernel_size=kwargs.get('kernel_size', 5),
                target_white=target_colors[1],
                target_black=target_colors[0]
            )
        elif method == 'instance':
            cleaned = clean_instance_mask(
                img, target_colors,
                method='nearest',
                min_object_size=kwargs.get('min_object_size', 50),
                kernel_size=kwargs.get('kernel_size', 3)
            )
        elif method == 'nearest':
            cleaned = cleaner.nearest_color_mapping(img, target_colors)
            kernel_size = kwargs.get('kernel_size', 3)
            if kernel_size > 0:
                cleaned = cleaner.morphology_clean(cleaned, kernel_size, 'open-close')
        elif method == 'cluster':
            cleaned = cleaner.hybrid_clean(img, target_colors, 'cluster-morph', **kwargs)
        else:
            cleaned = img
        
        # Save
        filename = os.path.basename(img_path)
        output_path = os.path.join(output_folder, filename)
        cv2.imwrite(output_path, cleaned)
    
    print(f"[Info] Batch cleaning complete, output to: {output_folder}")


if __name__ == "__main__":
    """Test example"""
    import sys
    
    print("="*70)
    print("Mask Cleaning Tool Test")
    print("="*70)
    
    # Create test image (simulate noisy mask from Gaussian rendering)
    test_img = np.zeros((480, 640, 3), dtype=np.uint8)
    
    # Add noisy red object
    cv2.rectangle(test_img, (100, 100), (300, 300), (0, 0, 255), -1)
    # Add black noise
    noise = np.random.randint(0, 50, (480, 640, 3), dtype=np.uint8)
    test_img = cv2.subtract(test_img, noise)
    
    # Add noisy green object
    cv2.rectangle(test_img, (350, 150), (550, 350), (0, 255, 0), -1)
    noise2 = np.random.randint(0, 30, (480, 640, 3), dtype=np.uint8)
    test_img = cv2.subtract(test_img, noise2)
    
    print("\nTest 1: Binary mask cleaning")
    cleaner = MaskCleaner()
    binary_cleaned = clean_binary_mask(test_img)
    print(f"  Input: Noisy red-green mask")
    print(f"  Output: Pure black-white mask")
    
    print("\nTest 2: Instance segmentation mask cleaning")
    target_colors = [(0, 0, 0), (0, 0, 255), (0, 255, 0)]  # Black, red, green
    instance_cleaned = clean_instance_mask(test_img, target_colors)
    print(f"  Input: Noisy multi-color mask")
    print(f"  Output: Pure color instance mask")
    
    print("\nTest 3: Extract dominant colors")
    dominant = extract_dominant_colors(test_img, num_colors=3)
    print(f"  Extracted dominant colors: {dominant}")
    
    print("\nTest complete")
    print("="*70)
